---
title: "Group 2: Final Report"
author: "Di Ye (diye2), Jingyi Xie (jingyix3), Zhenyu Gu (zgu15), Zihe Wang (zwang199)"
date: "November 29, 2018"
output: pdf_document
toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction
The stock data is from four companies, CME, CBOT, NYMEX and Comex. 

CME Group Inc. (Chicago Mercantile Exchange & Chicago Board of Trade) is an American financial market company operating an options and futures exchange. It owns and operates large derivatives and futures exchanges in Chicago, New York City, and exchange facilities in London, using online trading platforms. It also owns the Dow Jones stock and financial indexes, and CME Clearing Services, which provides settlement and clearing of exchange trades. The exchange-traded derivative contracts include futures and options based on interest rates, equity indexes, foreign exchange, energy, agricultural commodities, rare and precious metals, weather, and real estate.

CBo Territoria SA engages in the development, promotion and management of residential and business real estate properties based on Reunion Island. The company operates through the following segment: Property development and Land. The Property development segment engages in the development and management of its own real estate property, consisting primarily of business real estate: activity centers, offices and businesses. The Land segment offer land management and regional development. CBo Territoria was founded on January 16, 2004 and is headquartered in Sainte-Marie, Reunion Island.

The New York Mercantile Exchange (NYMEX) is a commodity futures exchange owned and operated by CME Group of Chicago. NYMEX is located at One North End Avenue in Brookfield Place in the Battery Park City section of Manhattan, New York City. Additional offices are located in Boston, Washington, Atlanta, San Francisco, Dubai, London, and Tokyo.

COMEX is the primary futures and options market for trading metals such as gold, silver, copper and aluminum. Formerly known as the Commodity Exchange Inc., COMEX merged with the New York Mercantile Exchange (NYMEX) in 1994 and became the division responsible for metals trading.

## Data Description
The datasets contain AlgoSeek Level 2 data from CME, CBOT, NYMEX and Comex. The Level 2 data is from the CME FIXFast feed which provides 10 levels of the book for the bid and the ask. The variables in the dataset are listed as below:
-	UTC: Timestamps in HHMMSSMMM in UTC time [MMM is for milliseconds] 
-	Ticker: Instrument name (up to 8 characters) 
-	Side: BUY/SELL side of the book
-	10 levels of: Price x Contracts (Number of Orders). For example “1.38 x 12 (5)” means there are 12 contracts at price 1.38 from a total of 5 orders. Each row has 10 levels but there will only be data for the number of Depth levels (see depth field above).

## Data Preparation

### Data Processing
The original data has ten column in textual form, eg. '2063.7500000 x 55 (28)'. We extracted the numeric value and used them to construct our feature matrix. We then processed the `Timestamp` to `s`, `m`, and `h` format matching to label data.

For each level, we makes the open price, close price, total number of contracts, total number of order, mean p and weighted average within a second for each side. Plus the grouping data `s`, `m`, and `h`, we have 124 feature for each observation.

### Data Cleaning
Some of the oberservation contains `NA`. This is  becasue in some seconds, there is no tansaction of `BUY`/`SELL`. We used `na.interpolation` and `na.replace` from R package `imputeTS` to fix the price of each level and set the volume to 0 if the price and volume are not available at a certain time.


## Exploratory Data
Before we started models, we have checked the labels and features to better understand the data. 

### Labels
Here are the plots of the distribution of the labels. We can observe from the plot that although there are more `stable` label, three directions `increasing`, `stable`, and `decreasing` approximately follow the Bernoulli distribution. 
![](label_dist.png)

### Stock Data.
We first plot the 

```{r}
s1 <- ggplot(ticker1[37500:38500,], aes(x = 37500:38500)) +
      geom_line(aes(y= Level1.Price.weighted.Buy, colour = "Weighted Avg")) +
      geom_line(aes(y= Level1.Volume.Buy/10, colour = "Volume")) +
      scale_y_continuous(sec.axis = sec_axis(~.*10, name = "Price"))
s2 <- ggplot(ticker1_label[37500:38500,], aes(x = 37500:38500, y = direction))+ geom_path()
arrangeGrob(s1, s2)
s1
grid.arrange(s2,s1, heights = c(1/5, 4/5)) 
plot(ticker1$Level1.Price.weighted.Buy, type = "l", xlab = "Level 1 Weighted Average Price", ylab = "Weighted Average Price")
```


## Data Transformation


## Model Comparison


```{r eval = FALSE, include=FALSE}


t1 <- fread("")

library(ggplot2)
library(data.table)
library(imputeTS)
ticker1_label <- fread("project data/Ticker1_label.csv")
ticker2_label <- fread("project data/Ticker2_label.csv")
ticker3_label <- fread("project data/Ticker3_label.csv")
ticker4_label <- fread("project data/Ticker4_label.csv")
ticker1 <- read.csv("data_level/ticker1_level.csv")
ticker2 <- read.csv("data_level/ticker2_level.csv")
ticker3 <- read.csv("data_level/ticker3_level.csv")
ticker4 <- read.csv("data_level/ticker4_level.csv")

ticker1_label$direction <- as.factor(ticker1_label$direction)
levels(ticker1_label$direction) <- c("Decrease", "Stable", "Increase")
ticker2_label$direction <- as.factor(ticker2_label$direction)
levels(ticker2_label$direction) <- c("Decrease", "Stable", "Increase")
ticker3_label$direction <- as.factor(ticker3_label$direction)
levels(ticker3_label$direction) <- c("Decrease", "Stable", "Increase")
ticker4_label$direction <- as.factor(ticker4_label$direction)
levels(ticker4_label$direction) <- c("Decrease", "Stable", "Increase")
all <- rbind(ticker1_label, ticker2_label)
all <- rbind(all, ticker3_label)
all <- rbind(all, ticker4_label)
lbs_plot <- ggplot(all, aes(x = ticker, fill = direction, group = direction)) + geom_bar(stat='count', position = "dodge")+coord_flip()
lbs_plot_all <- ggplot(all, aes(x = direction, fill = direction)) + geom_bar(stat='count', position = "dodge")
ggsave("label_dist.png", arrangeGrob(lbs_plot, lbs_plot_all))
```
```{r eval = FALSE, echo=FALSE}
ticker1[,c(4:43, 64:83)] <- na.interpolation(ticker1[,c(4:43, 64:83)], option = "linear")
ticker2[,c(4:43, 64:83)] <- na.interpolation(ticker2[,c(4:43, 64:83)], option = "linear")
ticker3[,c(4:43, 64:83)] <- na.interpolation(ticker3[,c(4:43, 64:83)], option = "linear")
ticker4[,c(4:43, 64:83)] <- na.interpolation(ticker4[,c(4:43, 64:83)], option = "linear")
ticker1 <- na.replace(ticker1, 0)
ticker2 <- na.replace(ticker2, 0)
ticker3 <- na.replace(ticker3, 0)
ticker4 <- na.replace(ticker4, 0)
```

```{r eval = FALSE, echo=FALSE}
plot(ticker1$Level1.Price.weighted.Buy, type = "l", xlab = "Level 1 Weighted Average Price", ylab = "Weighted Average Price")
lines(ticker1$Level1.Price.weighted.Sell,type = "l", col="green")
legend(3000, 2085, legend=c("Weighted Average Price 1 Buy", "Weighted Average Price 1 Sell"), col=c("black", "green"), lty=1, cex=0.7)

plot(ticker1$Level1.Volume.Buy, xlab = "Level 1 Volume", ylab = "Volume", type = "l")
lines(ticker1$Level1.Volume.Sell, type = "l", col="green")
legend(3000, 2085, legend=c("Weighted Average Price 1 Buy", "Weighted Average Price 1 Sell"), col=c("black", "green"), lty=1, cex=0.7)

plot(ticker2$Level1.Price.open.Buy, type = "l")
max(ticker2$Level1.Price.me.Buy)
min(ticker2$Level1.Price.me.Buy)
lines(ticker2$Level1.Price.open.Sell,type = "l", col="green")
# lines(ticker2$Level1.Price.me.Buy, type = "l", col = "red")
plot(ticker2$Level1.Volume.Buy)
lines(ticker2$Level1.Volume.Sell, type = "p", col="green")

plot(ticker3$Level1.Price.open.Buy, type = "l")
lines(ticker3$Level1.Price.open.Sell,type = "l", col="green")
# lines(ticker3$Level1.Price.me.Buy, type = "l", col = "red")
plot(ticker3$Level1.Volume.Buy)
lines(ticker3$Level1.Volume.Sell, type = "p", col="green")

plot(ticker4$Level1.Price.open.Buy, type = "l")
lines(ticker4$Level1.Price.open.Sell,type = "l", col="green")
# lines(ticker4$Level1.Price.me.Buy, type = "l", col = "red")
plot(ticker4$Level1.Volume.Buy)
lines(ticker4$Level1.Volume.Sell, type = "p", col="green")
```



```{r eval = FALSE, echo=FALSE}
#############ticker2 ###########
x_train2 <- ticker2[(1:floor(nrow(ticker2)/5*3)),]
x_val2 <- ticker2[((floor(nrow(ticker2)/5*3)+1):floor(nrow(ticker2)/5*4)),]
x_test2 <- ticker2[((floor(nrow(ticker2)/5*4)+1):nrow(ticker2)),]
y_train2 <- ticker2_label[(1:floor(nrow(ticker2)/5*3))]
y_val2 <- ticker2_label[((floor(nrow(ticker2)/5*3)+1):floor(nrow(ticker2)/5*4))]
y_test2 <- ticker2_label[((floor(nrow(ticker2)/5*4)+1):nrow(ticker2))]

col_Price.open.Buy <- 4:13
col_Price.open.Sell <- 14:23
col_Price.me.Buy <-24:33
col_Price.me.Sell <-34:43
col_Volume.Buy <-44:53
col_Volume.sell <-54:63
col_Price.weighted.Buy <-64:73
col_Price.weighted.Sell <-74:83

me_Price.open.Buy <- mean(as.matrix(as.data.frame(x_train2[,col_Price.open.Buy])))
sd_Price.open.Buy <- sd(as.matrix(x_train2[,col_Price.open.Buy]))

me_Price.open.Sell <- mean(as.matrix(x_train2[,col_Price.open.Sell]))
sd_Price.open.Sell <- sd(as.matrix(x_train2[,col_Price.open.Sell]))

me_Price.me.Buy <- mean(as.matrix(x_train2[,col_Price.me.Buy]))
sd_Price.me.Buy <- sd(as.matrix(x_train2[,col_Price.me.Buy]))

me_Price.me.Sell <- mean(as.matrix(x_train2[,col_Price.me.Sell]))
sd_Price.me.Sell <- sd(as.matrix(x_train2[,col_Price.me.Sell]))

me_Volume.Buy <- mean(as.matrix(x_train2[,col_Volume.Buy]))
sd_Volume.Buy <- sd(as.matrix(x_train2[,col_Volume.Buy]))

me_Volume.Sell <- mean(as.matrix(x_train2[,col_Volume.sell]))
sd_Volume.Sell <- sd(as.matrix(x_train2[,col_Volume.sell]))

me_Price.weighted.Buy <- mean(as.matrix(x_train2[,col_Price.weighted.Buy]))
sd_Price.weighted.Buy <- sd(as.matrix(x_train2[,col_Price.weighted.Buy]))

me_Price.weighted.Sell <- mean(as.matrix(x_train2[,col_Price.weighted.Sell]))
sd_Price.weighted.Sell <- sd(as.matrix(x_train2[,col_Price.weighted.Sell]))

# rescale train data
for(i in 4:13) x_train2[,i] <- scale(x_train2[,i], center = me_Price.open.Buy, scale = sd_Price.open.Buy)
for(i in 14:23) x_train2[,i] <- scale(x_train2[,i], center = me_Price.open.Sell, scale = sd_Price.open.Sell)
for(i in 24:33) x_train2[,i] <- scale(x_train2[,i], center = me_Price.me.Buy, scale = sd_Price.me.Buy)
for(i in 34:43) x_train2[,i] <- scale(x_train2[,i], center = me_Price.me.Sell, scale = sd_Price.me.Sell)
for(i in 44:53) x_train2[,i] <- scale(x_train2[,i], center = me_Volume.Buy, scale = sd_Volume.Buy)
for(i in 54:63) x_train2[,i] <- scale(x_train2[,i], center = me_Volume.Sell, scale = sd_Volume.Sell)
for(i in 64:73) x_train2[,i] <- scale(x_train2[,i], center = me_Price.weighted.Buy,
                                      scale = sd_Price.weighted.Buy)
for(i in 74:83) x_train2[,i] <- scale(x_train2[,i], center = me_Price.weighted.Sell, 
                                      scale = sd_Price.weighted.Sell)
X_data_train <- x_train2[,(1:83)]
Y_data_train <- y_train2$direction

# rescale validation data (using train mean and sd)
for(i in 4:13) x_val2[,i] <- scale(x_val2[,i], center = me_Price.open.Buy, scale = sd_Price.open.Buy)
for(i in 14:23) x_val2[,i] <- scale(x_val2[,i], center = me_Price.open.Sell, scale = sd_Price.open.Sell)
for(i in 24:33) x_val2[,i] <- scale(x_val2[,i], center = me_Price.me.Buy, scale = sd_Price.me.Buy)
for(i in 34:43) x_val2[,i] <- scale(x_val2[,i], center = me_Price.me.Sell, scale = sd_Price.me.Sell)
for(i in 44:53) x_val2[,i] <- scale(x_val2[,i], center = me_Volume.Buy, scale = sd_Volume.Buy)
for(i in 54:63) x_val2[,i] <- scale(x_val2[,i], center = me_Volume.Sell, scale = sd_Volume.Sell)
for(i in 64:73) x_val2[,i] <- scale(x_val2[,i], center = me_Price.weighted.Buy,
                                      scale = sd_Price.weighted.Buy)
for(i in 74:83) x_val2[,i] <- scale(x_val2[,i], center = me_Price.weighted.Sell, 
                                      scale = sd_Price.weighted.Sell)
X_data_val <- x_val2[,(1:83)]
Y_data_val <- y_val2$direction

# rescale test data (using train mean and sd)
for(i in 4:13) x_test2[,i] <- scale(x_test2[,i], center = me_Price.open.Buy, scale = sd_Price.open.Buy)
for(i in 14:23) x_test2[,i] <- scale(x_test2[,i], center = me_Price.open.Sell, scale = sd_Price.open.Sell)
for(i in 24:33) x_test2[,i] <- scale(x_test2[,i], center = me_Price.me.Buy, scale = sd_Price.me.Buy)
for(i in 34:43) x_test2[,i] <- scale(x_test2[,i], center = me_Price.me.Sell, scale = sd_Price.me.Sell)
for(i in 44:53) x_test2[,i] <- scale(x_test2[,i], center = me_Volume.Buy, scale = sd_Volume.Buy)
for(i in 54:63) x_test2[,i] <- scale(x_test2[,i], center = me_Volume.Sell, scale = sd_Volume.Sell)
for(i in 64:73) x_test2[,i] <- scale(x_test2[,i], center = me_Price.weighted.Buy,
                                      scale = sd_Price.weighted.Buy)
for(i in 74:83) x_test2[,i] <- scale(x_test2[,i], center = me_Price.weighted.Sell, 
                                      scale = sd_Price.weighted.Sell)
X_data_test <- x_test2[,(1:83)]
Y_data_test <- y_test2$direction
```




```{r eval=FALSE, include=FALSE}
library(keras)
checkPoint <- callback_model_checkpoint(filepath = file.path("lob_A.h5"),
                                        monitor = "val_acc", save_best_only = TRUE)
reduceLr <- callback_reduce_lr_on_plateau(monitor = "val_acc", factor = 0.1, patience = 3)
logger <- callback_csv_logger(file.path("logger-lob_A.csv"))
  
callbacks_list <- list(
  callback_early_stopping(
    monitor = "acc",
    patience = 1
  ),
  callback_model_checkpoint(
    filepath = "my_model.h5",
    monitor = "val_loss",
    save_best_only = TRUE
  )
)

sampling_generator0 <- function(X_data, Y_data, batch_size, w)
{
  function()
  {
    rows <- sample(1:(nrow(X_data)-w+1), batch_size, replace = TRUE)
    tmp <- Y <- X <- NULL
    for(i in rows)
    {
      tmp <- rbind(tmp, as.vector(as.matrix(X_data[(i:(i+w-1)),])))
      Y <- c(Y, Y_data[i+w-1])
    }
    X <- array_reshape(tmp, c(batch_size, w, ncol(X_data), 1), order = "F") # a little difference: the last axis is included for the feature dimension
    Y <- to_categorical(Y, num_classes = 3)
    list(X, Y)
  }
}

k_clear_session()
x_train <- as.matrix(X_data_train)
y_train <- as.numeric(Y_data_train)
x_val <- as.matrix(X_data_val)
y_val <- as.numeric(Y_data_val)
x_test <- as.matrix(X_data_test)
y_test <- as.numeric(Y_data_test)
nCol <- ncol(x_train)

model <- keras_model_sequential() %>% 
  layer_conv_2d(filters = 16, kernel_size = c(4, nCol), activation = "relu", input_shape = c(100, nCol, 1)) %>% 
  layer_conv_2d(filters = 16, kernel_size = c(1, 1), activation = "relu") %>% 
  layer_conv_2d(filters = 16, kernel_size = c(4, 1), activation = "relu") %>% 
  layer_flatten() %>% 
  layer_dense(units = 8, activation = "relu") %>% 
  layer_dense(units = 3, activation = "softmax")

model %>% compile(
  loss = "categorical_crossentropy",
  optimizer = optimizer_rmsprop(lr = 1e-4),
  metrics = c("acc")
)
w <- 100

his <- model %>% fit_generator(sampling_generator0(x_train, y_train, batch_size = 100, w=100),
                               steps_per_epoch = floor((nrow(x_train)-w+1) / 100), epochs = 10,
                               callbacks = callbacks_list,
                               validation_data = sampling_generator0(x_val, y_val, batch_size = 20,
                                                                    w=100),
                               validation_steps = floor((nrow(x_val)-w+1) / 100))
plot(his)


nCol <- ncol(X_data_train)
w <- 30
model <- keras_model_sequential() %>%
layer_conv_2d(filters = 64, kernel_size = c(4, nCol), activation = "relu", input_shape = c(w, nCol, 1)) %>%
layer_conv_2d(filters = 16, kernel_size = c(1, 1), activation = "relu") %>%
layer_conv_2d(filters = 8, kernel_size = c(4, 1), activation = "relu") %>%
layer_flatten() %>%
layer_dense(units = 8, activation = "relu") %>%
layer_dropout(rate = 0.2) %>%
layer_dense(units = 3, activation = "softmax")

summary(model)
model %>% compile(
loss = "categorical_crossentropy",
optimizer = "adam",
metrics = c("acc")
)
batch_size <- 120
his0 <- model %>% fit_generator(sampling_generator0(X_data_train, Y_data_train, batch_size = batch_size, w=w),
                                 steps_per_epoch = floor((nrow(X_data_train)-w+1) / batch_size), epochs = 10,
                                 callbacks = list(checkPoint, reduceLr, logger),
                                 validation_data = sampling_generator0(X_data_val, Y_data_val, batch_size = batch_size, w=w),
                                 validation_steps = floor((nrow(X_data_val)-w+1) / batch_size))
plot(his0)


model <- keras_model_sequential() %>%
  layer_cudnn_gru(unit=8, input_shape = list(NULL, nCol), return_sequences = TRUE) %>%
  # layer_cudnn_gru(unit=16) %>%
  layer_dense(units = 3, activation = "softmax")

model %>% compile(
  loss = "categorical_crossentropy",
  optimizer = optimizer_rmsprop(lr = 1e-4),
  metrics = c("acc")
)

#############
# run model #
#############
batch_size <- 100
his <- model %>% fit_generator(sampling_generator0(X_data_train, Y_data_train, batch_size = batch_size, w=w),
                               steps_per_epoch = floor((nrow(X_data_train)-w+1) / batch_size), epochs = 20,
                               callbacks = list(checkPoint, reduceLr, logger)
                               # validation_data = sampling_generator(X_data_val, Y_data_val, batch_size = batch_size, w=w),
                               # validation_steps = floor((nrow(X_data_val)-w+1) / batch_size)
                               )
plot(his)
fitted_B <- load_model_hdf5(file.path(work_folder, "lob_B.h5"))

results_B <- fitted_B %>% evaluate_generator(sampling_generator(X_data_test, Y_data_test, batch_size = batch_size, w=w), 
                                         steps = floor((nrow(X_data_test)-w+1) / batch_size))
results_B


model <- keras_model_sequential() %>%
layer_lstm(units = 256, input_shape = (1, 4), return_sequences = T)
layer_conv_2d(filters = 8, kernel_size = c(4, 4), activation = "relu", input_shape = c(w, 4, 1)) %>%
layer_conv_2d(filters = 8, kernel_size = c(1, 1), activation = "relu") %>%
# layer_conv_lstm_2d(filters = 8, kernel_size = c(4, 1), activation = "relu") %>%
layer_conv_2d(filters = 8, kernel_size = c(4, 1), activation = "relu") %>%
# layer_conv_lstm_2d(filters = 8, kernel_size = c(4, 1), activation = "relu") %>%
layer_flatten() %>%
layer_dense(units = 8, activation = "relu") %>%
layer_lstm(units = 8, return_sequences=T) %>% 
# layer_dropout(rate = 0.5) %>%
layer_dense(units = 8, activation = "softmax")

model %>% compile(
loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(lr = 1e-4),
metrics = c("acc")
)
batch_size <- 120
his0 <- model %>% fit_generator(sampling_generator0(X_data_train, Y_data_train, batch_size = batch_size, w=w),
                                 steps_per_epoch = floor((nrow(X_data_train)-w+1) / batch_size), epochs = 10,
                                 callbacks = list(checkPoint, reduceLr, logger))
                                 # validation_data = sampling_generator0(X_data_val, Y_data_val, batch_size = batch_size, w=w),
                                 # validation_steps = floor((nrow(X_data_val)-w+1) / batch_size)
plot(his0)
```

